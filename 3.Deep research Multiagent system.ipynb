{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e3ebc4-57af-4fe4-bdd3-36aff67bf276",
   "metadata": {},
   "source": [
    "# Deep research Multiagent system\n",
    "\n",
    "\n",
    "### Original doc:\n",
    "\n",
    "    https://www.youtube.com/watch?v=mjPSkPLbu1s\n",
    "\n",
    "<div style=\"width: 100%; height: 768px; overflow: hidden;\">\n",
    "  <iframe width=\"1024\" height=\"768\" src=\"https://www.youtube.com/embed/mjPSkPLbu1s?si=nrN8Y4pnHNAj-5WZ\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d30b6f7-3bec-4d9f-af50-43dfdc81ae6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:42.364369Z",
     "start_time": "2024-05-15T08:19:42.359273Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U pip langgraph langchain_community langchain_anthropic langchain-tavily langchain_experimental langchain_ollama mcp langchain-mcp-adapters langchain-google-genai langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30c2f3de-c730-4aec-85a6-af2c2f058803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:42.395571Z",
     "start_time": "2024-05-15T08:19:42.365662Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# load environment variables from .env file\n",
    "load_dotenv()\n",
    "workfolder = os.getenv('WORKFOLDER')\n",
    "mcp_file_path = os.getenv('MCP_SRV_PATH')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffd0c4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='get_current_time', description='Returns current system time.', args_schema={'description': 'Returns current system time.', 'properties': {}, 'title': 'get_current_time', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x717fae5d1580>),\n",
       " StructuredTool(name='web_search', description='A Internet search engine. Useful for when you need to answer questions about current events', args_schema={'description': 'A Internet search engine. Useful for when you need to answer questions about current events', 'properties': {'query': {'description': 'search query to look up', 'title': 'Query', 'type': 'string'}, 'num_results': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': 5, 'description': 'Max search results per query to return (default: 5)', 'title': 'Num Results'}}, 'required': ['query'], 'title': 'web_search', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x717fae7c8a40>),\n",
       " StructuredTool(name='scrape_webpages', description='Scrape and read the provided web page url for detailed information', args_schema={'description': 'Scrape and read the provided web page url for detailed information', 'properties': {'url': {'description': 'The URL of the webpage to scrape', 'title': 'Url', 'type': 'string'}}, 'required': ['url'], 'title': 'scrape_webpages', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x717fae7c8cc0>),\n",
       " StructuredTool(name='read_file', description='Read content from a file.', args_schema={'description': 'Read content from a file.', 'properties': {'file_path': {'description': 'Path to the file to read', 'title': 'File Path', 'type': 'string'}, 'encoding': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': 'utf-8', 'description': 'The encoding of the file.', 'title': 'Encoding'}, 'start': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': 0, 'description': 'The start line. Default is 0', 'title': 'Start'}, 'end': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'The end line. Default is None', 'title': 'End'}}, 'required': ['file_path'], 'title': 'read_file', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x717fae7c8d60>),\n",
       " StructuredTool(name='write_file', description='Writes text content to a file in append or overwrite mode.', args_schema={'description': 'Writes text content to a file in append or overwrite mode.', 'properties': {'file_path': {'description': 'The full path to the file where content will be written.', 'title': 'File Path', 'type': 'string'}, 'mode': {'description': \"Mode in which the file is opened. 'w' for writing, 'x' for creating and writing to a new file, and 'a' for appending\", 'enum': ['w', 'x', 'a'], 'title': 'Mode', 'type': 'string'}, 'content': {'description': 'The content to be written to the file.', 'title': 'Content', 'type': 'string'}, 'encoding': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': 'utf-8', 'description': 'The encoding of the file.', 'title': 'Encoding'}}, 'required': ['file_path', 'mode', 'content'], 'title': 'write_file', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x717fae7cb240>),\n",
       " StructuredTool(name='execute_bash', description='Execute a bash command.', args_schema={'description': 'Execute a bash command.', 'properties': {'command': {'description': 'The bash command to execute', 'title': 'Command', 'type': 'string'}, 'timeout': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': 60, 'description': 'Timeout in seconds.', 'title': 'Timeout'}}, 'required': ['command'], 'title': 'execute_bash', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x717fae7c99e0>)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='web_search' description='A Internet search engine. Useful for when you need to answer questions about current events' args_schema={'description': 'A Internet search engine. Useful for when you need to answer questions about current events', 'properties': {'query': {'description': 'search query to look up', 'title': 'Query', 'type': 'string'}, 'num_results': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': 5, 'description': 'Max search results per query to return (default: 5)', 'title': 'Num Results'}}, 'required': ['query'], 'title': 'web_search', 'type': 'object'} response_format='content_and_artifact' coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x717fae7c8a40>\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional, Literal, TypedDict\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "client = MultiServerMCPClient({\"mcp\": {\"command\": \"python\",\"args\": [mcp_file_path], \"transport\": \"stdio\", }})\n",
    "tools = await client.get_tools()\n",
    "display(tools)\n",
    "\n",
    "def get_tool(name: str):\n",
    "    return next((tool for tool in tools if tool.name == name), None)\n",
    "\n",
    "print(get_tool('web_search'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46fed548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "llm_model = ChatOllama(model=\"qwen3\")\n",
    "# llm_model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2)\n",
    "# llm_model = ChatOpenAI(model=\"qwen-plus\", api_key=os.getenv('DASHSCOPE_API_KEY'), base_url=os.getenv('DASHSCOPE_BASE_URL'))\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler() \n",
    "llm_config = {\"configurable\": {\"thread_id\": \"abc123\"}, \"recursion_limit\": 20, \"callbacks\": [langfuse_handler]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b21c0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "from typing import TypedDict\n",
    "\n",
    "topic_analizer_prompt = \"\"\" \n",
    "You are a topic analizer. \n",
    "Your goal is to generate 4 questions that, together, cover the topic.\n",
    "output format :\n",
    "**question 1**:\n",
    "**question 2**:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# # Define structured output schema\n",
    "# class TopicAnalysis(TypedDict):\n",
    "#     topic: str\n",
    "#     questions: list[str]\n",
    "    \n",
    "# Create the agent\n",
    "topic_analizer = create_agent(name=\"topic_analizer\", model=llm_model, \n",
    "    system_prompt=topic_analizer_prompt, \n",
    "    # response_format=ToolStrategy(TopicAnalysis)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "499c6f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the agent\n",
    "# input_message = {\"role\": \"user\", \"content\": \"multi-agent deep research system using langchain in local ollama qwen3\"}\n",
    "# async for step in topic_analizer.astream(\n",
    "#     {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "# ):\n",
    "#     step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "240354bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "from typing import TypedDict\n",
    "\n",
    "search_agent_prompt = \"\"\" \n",
    "You are a Internet search assistant.\n",
    "Your goal is to find information from web search.\n",
    "Get 2 results for a given query string. \n",
    "Do not elaborate, do not ask any questions\n",
    "1. Optimize the query string before search on the Internet\n",
    "2. output format:\n",
    "**url 1**:\n",
    "**url 2**:\n",
    "\"\"\"\n",
    "\n",
    "# # Define structured output schema\n",
    "# class SearchItem(TypedDict):\n",
    "#     href: str\n",
    "#     # title: str\n",
    "#     # body: str\n",
    "\n",
    "# class SearchFormat(TypedDict):\n",
    "#     summary: str\n",
    "#     # results: list[SearchItem]\n",
    "    \n",
    "# Create the agent\n",
    "search_agent = create_agent(name=\"search_agent\", model=llm_model, tools=[get_tool('web_search')], \n",
    "    system_prompt=search_agent_prompt, \n",
    "    # response_format=ToolStrategy(SearchFormat)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67934853",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_message = {\"role\": \"user\", \"content\": \"\"\"**question 1**:  \n",
    "What are the key components and architecture required to build a multi-agent deep research system using LangChain and Ollama's Qwen3 model?\"\"\"\n",
    "}\n",
    "\n",
    "# # Use the agent\n",
    "# async for step in search_agent.astream(\n",
    "#     {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "# ):\n",
    "#     step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b5dc4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create the agent\n",
    "summarization_agent_prompt = \"\"\" \n",
    "You are a summarization assistant \n",
    "1. For each url scrape the web pages for detailed information.\n",
    "2. Summarize each source in 2-4 concise bullet points.\n",
    "2. output format:\n",
    "**url 1**:\n",
    "**summary**:\n",
    "**url 2**:\n",
    "**summary**:\n",
    "\"\"\"\n",
    "summarization_agent = create_agent(name=\"summarization_agent\", model=llm_model, tools=[get_tool('scrape_webpages')], system_prompt=summarization_agent_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ef1027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = {\"role\": \"user\", \"content\": \"\"\"**url 1**:  \n",
    "https://composio.dev/blog/deep-research-agent-qwen3-using-langgraph-and-ollama  \n",
    "**url 2**:  \n",
    "https://www.freecodecamp.org/news/build-a-local-ai/  \"\"\"\n",
    "  }\n",
    "\n",
    "# # Use the agent\n",
    "# async for step in summarization_agent.astream(\n",
    "#     {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "# ):\n",
    "#     step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e09fb60f-1aac-455b-b67d-8d2e4ccfd747",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:46.559082Z",
     "start_time": "2024-05-15T08:19:44.541330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List, Optional, Literal, TypedDict\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, trim_messages\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "async def make_supervisor_node(llm: BaseChatModel, members: list[str]) -> str:\n",
    "    options = [\"FINISH\"] + members\n",
    "\n",
    "    class Router(TypedDict):\n",
    "        \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "        next: Literal[*options]\n",
    "\n",
    "    supervisor_system_prompt = f\"\"\"\n",
    "You are a supervisor tasked with managing a conversation between the following workers: {members}. \n",
    "Given the following user request, respond with the worker to act next. \n",
    "Break multiple lines outputs into single separate items requests to the workers. \n",
    "Each worker will perform a task and respond with their results. \n",
    "When finished, respond with FINISH. /think\"\"\"\n",
    "\n",
    "    async def supervisor_node(state: State) -> Command[Literal[*members, \"__end__\"]]:\n",
    "        \"\"\"An LLM-based router.\"\"\"\n",
    "        messages = [ {\"role\": \"system\", \"content\": supervisor_system_prompt},] + state[\"messages\"]\n",
    "        response = await llm.with_structured_output(Router).ainvoke(messages)\n",
    "        goto = response[\"next\"]\n",
    "        if goto == \"FINISH\":\n",
    "            goto = END\n",
    "\n",
    "        return Command(\n",
    "            update={\"next\": goto},\n",
    "            goto=goto, \n",
    "            )\n",
    "\n",
    "    return supervisor_node\n",
    "\n",
    "\n",
    "async def topic_analizer_node(state: State) -> Command[Literal[\"search_agent\"]]:\n",
    "    result = await topic_analizer.ainvoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"topic_analizer\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"search_agent\",\n",
    "    )\n",
    "\n",
    "async def search_agent_node(state: State) -> Command[Literal[\"summarization_agent\"]]:\n",
    "    result = await search_agent.ainvoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"search_agent\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"summarization_agent\",\n",
    "    )\n",
    "\n",
    "async def summarization_agent_node(state: State) -> Command[Literal[\"__end__\"]]:\n",
    "    result = await summarization_agent.ainvoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"summarization_agent\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"__end__\",\n",
    "    )\n",
    "\n",
    "research_builder = StateGraph(State)\n",
    "\n",
    "# research_supervisor_node = await make_supervisor_node(llm_model, [\"topic_analizer\", \"search_agent\", \"summarization_agent\"])\n",
    "# research_builder.add_edge(START, \"supervisor\")\n",
    "# research_builder.add_node(\"supervisor\", research_supervisor_node)\n",
    "# research_builder.add_node(\"topic_analizer\", topic_analizer_node)\n",
    "# research_builder.add_node(\"search_agent\", search_agent_node)\n",
    "# research_builder.add_node(\"summarization_agent\", summarization_agent_node)\n",
    "\n",
    "research_builder.add_edge(START, \"topic_analizer\")\n",
    "research_builder.add_node(\"topic_analizer\", topic_analizer_node)\n",
    "research_builder.add_node(\"search_agent\", search_agent_node)\n",
    "research_builder.add_node(\"summarization_agent\", summarization_agent_node)\n",
    "\n",
    "\n",
    "research_graph = research_builder.compile()\n",
    "display(Image(research_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2801266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "multi-agent deep research system using langchain in local ollama qwen3\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: topic_analizer\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking about a multi-agent deep research system using LangChain with local Ollama and Qwen3. Let me break down what they need. First, I should figure out the key components here. Multi-agent systems involve multiple AI agents working together, so I need to cover how they interact. LangChain is for building applications with LLMs, so maybe questions about integrating LangChain with Ollama. Ollama is a local LLM runtime, so using it with Qwen3, which is a model from Alibaba. \n",
      "\n",
      "The user might be looking to set up a local environment for research. So questions about setting up the local environment with Ollama and Qwen3. Then, how to structure the agentsâ€”like roles, communication protocols. Also, how to handle complex tasks with multiple agents. Maybe data handling and processing in such a system. Wait, the user mentioned \"deep research,\" so maybe they need to handle large data or complex workflows. \n",
      "\n",
      "I need to make sure the questions cover setup, integration, agent interaction, and task management. Let me check if I missed anything. Oh, maybe how to evaluate the system's effectiveness. But the user might be more focused on the technical setup and operation. Let me structure four questions: setup with Ollama and Qwen3, agent architecture, task decomposition, and communication protocols. That should cover the main aspects.\n",
      "</think>\n",
      "\n",
      "**question 1**:  \n",
      "How can I set up a local environment using Ollama to run Qwen3 and integrate it with LangChain for multi-agent collaboration?  \n",
      "\n",
      "**question 2**:  \n",
      "What are the key architectural considerations for designing a multi-agent system with LangChain, Ollama, and Qwen3 to enable seamless task delegation and coordination?  \n",
      "\n",
      "**question 3**:  \n",
      "How does LangChain facilitate the creation of complex workflows in a multi-agent research system, and what role does Qwen3 play in enhancing decision-making processes?  \n",
      "\n",
      "**question 4**:  \n",
      "What challenges might arise when implementing a deep research system with local Ollama and Qwen3, and how can they be mitigated through agent communication protocols and data management strategies?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: search_agent\n",
      "\n",
      "<think>\n",
      "Okay, let's see. The user asked about a multi-agent deep research system using LangChain with local Ollama and Qwen3. I need to find two relevant results.\n",
      "\n",
      "First, I'll optimize the query. The original query is a bit long, so breaking it down into key terms: \"multi-agent system,\" \"LangChain,\" \"local Ollama,\" \"Qwen3,\" and \"research.\" Maybe rephrase to something like \"multi-agent research system LangChain Ollama Qwen3\" to get more precise results.\n",
      "\n",
      "Now, looking at the tool response. The first result is about Qwen3 Coder building multi-agent systems with LangChain. That seems directly relevant. The second result is from Medium about building multi-agent systems with LangGraph and Ollama. While it mentions LangGraph instead of LangChain, it's still related to multi-agent systems using Ollama. The user might be okay with similar tools, so this could be a good second result. \n",
      "\n",
      "I should check if these URLs are about research systems. The first link mentions \"deep research\" in the title, which matches the user's query. The second link talks about architectures and code, which could be part of a research setup. Even though it's about LangGraph, it's still within the scope of multi-agent systems using Ollama. \n",
      "\n",
      "So, the two URLs provided in the tool response are the best matches. They cover both Qwen3 and Ollama integration with LangChain/LangGraph, which aligns with the user's request. No need to adjust further; these are the top results.\n",
      "</think>\n",
      "\n",
      "**url 1**:  \n",
      "https://qwen3lm.com/qwen3-multi-agent-systems/  \n",
      "\n",
      "**url 2**:  \n",
      "https://medium.com/@diwakarkumar_18755/building-multi-agent-systems-with-langgraph-and-ollama-architectures-concepts-and-code-383d4c01e00c\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: summarization_agent\n",
      "\n",
      "<think>\n",
      "Okay, let me break this down. The user is asking about a multi-agent deep research system using LangChain with local Ollama and Qwen3. First, I need to understand what each component does. LangChain is a framework for building applications with large language models, right? Ollama is a tool for running local LLMs, and Qwen3 is a specific model from Alibaba. \n",
      "\n",
      "The user wants to set up a system where multiple agents work together, probably for research purposes. So, the key points would be integrating LangChain with Ollama to run Qwen3 locally. Maybe they need to handle complex tasks by splitting them into agents, each using Qwen3. \n",
      "\n",
      "I should check if there are resources or guides on setting up such a system. The first URL mentioned is about Qwen3 and multi-agent systems, which seems relevant. The second URL is from Medium discussing multi-agent systems with LangGraph and Ollama. Even though it's LangGraph instead of LangChain, it's still about multi-agent systems using Ollama, which might be useful.\n",
      "\n",
      "Wait, the user specifically mentioned LangChain, so maybe the second URL isn't directly relevant. But since the user might be looking for similar concepts, it's still a good resource. The first URL is more aligned with Qwen3 and LangChain, so that's better. \n",
      "\n",
      "I need to make sure the summaries capture the main points: setting up the environment, agent architecture, task decomposition, and communication protocols. Also, mention how LangChain and Ollama integrate with Qwen3 for research. The user might be interested in both the technical setup and the research applications. \n",
      "\n",
      "So, the summaries should highlight the integration steps, system architecture, task handling, and communication methods. That should cover the user's needs for building a multi-agent research system.\n",
      "</think>\n",
      "\n",
      "**url 1**:  \n",
      "https://qwen3lm.com/qwen3-multi-agent-systems/  \n",
      "\n",
      "**summary**:  \n",
      "- Focuses on building multi-agent systems using Qwen3, emphasizing collaboration between agents for complex problem-solving.  \n",
      "- Highlights integration with LangChain for task decomposition, memory management, and dynamic role assignment.  \n",
      "- Discusses scalability and real-time decision-making in research scenarios using local Ollama deployment.  \n",
      "\n",
      "**url 2**:  \n",
      "https://medium.com/@diwakarkumar_18755/building-multi-agent-systems-with-langgraph-and-ollama-architectures-concepts-and-code-383d4c01e00c  \n",
      "\n",
      "**summary**:  \n",
      "- Explains architectures for multi-agent systems using LangGraph (similar to LangChain) and Ollama for local LLM execution.  \n",
      "- Covers agent communication protocols, state management, and workflow orchestration for research applications.  \n",
      "- Provides code examples for deploying agents with Ollama and Qwen3-like models in a decentralized setup.\n"
     ]
    }
   ],
   "source": [
    "messages = {\"messages\": [(\"user\", \"multi-agent deep research system using langchain in local ollama qwen3\")]}\n",
    "async for step in research_graph.astream(messages, config=llm_config, stream_mode=\"values\" ):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcdbf44-9481-430c-8429-fa142ed8a626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:53.677722Z",
     "start_time": "2024-05-15T08:19:51.953933Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"qwen3\")\n",
    "\n",
    "doc_writer_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[write_file, edit_document, read_file],\n",
    "    prompt=(\n",
    "        \"You can read, write and edit documents based on note-taker's outlines. \"\n",
    "        \"Don't ask follow-up questions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def doc_writing_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = doc_writer_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"doc_writer\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "note_taking_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[create_outline, read_file],\n",
    "    prompt=(\n",
    "        \"You can read documents and create outlines for the document writer. \"\n",
    "        \"Don't ask follow-up questions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def note_taking_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = note_taking_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"note_taker\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "chart_generating_agent = create_react_agent(\n",
    "    llm, tools=[read_file, python_repl_tool]\n",
    ")\n",
    "\n",
    "\n",
    "def chart_generating_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = chart_generating_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "doc_writing_supervisor_node = make_supervisor_node(\n",
    "    llm, [\"doc_writer\", \"note_taker\", \"chart_generator\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee2cd9b-29aa-458e-903d-4e49179e5d59",
   "metadata": {},
   "source": [
    "With the objects themselves created, we can form the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c644f-8966-4d2e-98d2-80d73520e9fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:53.693123Z",
     "start_time": "2024-05-15T08:19:53.678906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the graph here\n",
    "paper_writing_builder = StateGraph(State)\n",
    "paper_writing_builder.add_node(\"supervisor\", doc_writing_supervisor_node)\n",
    "paper_writing_builder.add_node(\"doc_writer\", doc_writing_node)\n",
    "paper_writing_builder.add_node(\"note_taker\", note_taking_node)\n",
    "paper_writing_builder.add_node(\"chart_generator\", chart_generating_node)\n",
    "\n",
    "paper_writing_builder.add_edge(START, \"supervisor\")\n",
    "paper_writing_graph = paper_writing_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7d1e48a9c39a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:32:13.913188Z",
     "start_time": "2024-05-15T08:32:11.598993Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(paper_writing_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860fd46-c24d-40a5-a6ba-e8fddcd43369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:53.723467Z",
     "start_time": "2024-05-15T08:19:53.709307Z"
    }
   },
   "outputs": [],
   "source": [
    "# for s in paper_writing_graph.stream(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             (\n",
    "#                 \"user\",\n",
    "#                 \"Write an outline for poem about cats and then write the poem to disk.\",\n",
    "#             )\n",
    "#         ]\n",
    "#     },\n",
    "#     {\"recursion_limit\": 100, \"callbacks\": [langfuse_handler]},\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5b08d-9a9a-474a-94b4-f7aaa8ff19e6",
   "metadata": {},
   "source": [
    "## Add Layers\n",
    "\n",
    "In this design, we are enforcing a top-down planning policy. We've created two graphs already, but we have to decide how to route work between the two.\n",
    "\n",
    "We'll create a _third_ graph to orchestrate the previous two, and add some connectors to define how this top-level state is shared between the different graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbfbe34-43f5-4a3d-8e9b-6a1d9b339aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "teams_supervisor_node = make_supervisor_node(llm, [\"research_team\", \"writing_team\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4880e573-612f-4d24-97c1-2079382a4a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:55.469348Z",
     "start_time": "2024-05-15T08:19:55.455831Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_research_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = research_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=response[\"messages\"][-1].content, name=\"research_team\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "def call_paper_writing_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = paper_writing_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=response[\"messages\"][-1].content, name=\"writing_team\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Define the graph.\n",
    "super_builder = StateGraph(State)\n",
    "super_builder.add_node(\"supervisor\", teams_supervisor_node)\n",
    "super_builder.add_node(\"research_team\", call_research_team)\n",
    "super_builder.add_node(\"writing_team\", call_paper_writing_team)\n",
    "\n",
    "super_builder.add_edge(START, \"supervisor\")\n",
    "super_graph = super_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ff3ae26cd42ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:32:33.694459Z",
     "start_time": "2024-05-15T08:32:31.524790Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(super_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8badbf-d728-44bd-a2a7-5b4e587c92fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:55.796497Z",
     "start_time": "2024-05-15T08:19:55.796497Z"
    }
   },
   "outputs": [],
   "source": [
    "for s in super_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"Research AI agents and write in a file using the writing_team a brief report about them.\")\n",
    "        ],\n",
    "    },\n",
    "    {\"recursion_limit\": 150, \"callbacks\": [langfuse_handler]},\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
