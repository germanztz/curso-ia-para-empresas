{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e3ebc4-57af-4fe4-bdd3-36aff67bf276",
   "metadata": {},
   "source": [
    "# 1. Client Mail Agents ğŸ“Œ\n",
    "\n",
    "### **Que aprenderemos** ğŸ“š\n",
    "1. ğŸ§  Utiliza Langchain agents.  \n",
    "1. ğŸ› ï¸ Usar el agente para programar y utilizar sus propias Tools.  \n",
    "1. ğŸ’¡ No requiere suscripciones, utiliza solamente modelos de LLM locales y ligeros, en este caso usamos `qwen3:7b` sobre `ollama`.\n",
    "\n",
    "### **De quÃ© trata el proyecto** ğŸ“š\n",
    "Este proyecto realiza operaciones sobre los clientes de una empresa. \n",
    "En este caso, consulta los clientes de una empresa y genera un e-mail utilizando el idioma prefrido del cliente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1004d8",
   "metadata": {},
   "source": [
    "### **InstalaciÃ³n de pre-requisitos** ğŸš€\n",
    "\n",
    "Esta lÃ­nea es una instrucciÃ³n para instalar paquetes de software en tu entorno de programaciÃ³n de Python. Es similar a usar `pip install` en la terminal, pero el `%` al principio es una \"magic command\" que se usa en entornos interactivos como Jupyter Notebook o Google Colab.\n",
    "\n",
    "**Â¿CÃ³mo funciona?** ğŸ§ \n",
    "\n",
    "1. **`%pip`:** Invoca el instalador de paquetes de Python, `pip`. ğŸ› ï¸\n",
    "2. **`install`:** Le dice a `pip` que queremos instalar algo. ğŸ“¦\n",
    "3. **`-U --upgrade`:** Estas son opciones. `-U` es una forma abreviada de `--upgrade`. Juntas, le dicen a `pip` que actualice los paquetes a la Ãºltima versiÃ³n si ya estÃ¡n instalados. ğŸ”§\n",
    "4. **`pip`:** Este es el gestor de paquetes de Python. Es como una tienda donde puedes encontrar e instalar bibliotecas y herramientas creadas por otros programadores. ğŸ›ï¸\n",
    "5. **`langgraph langchain_ollama`:** Estos son los nombres de los paquetes especÃ­ficos que queremos instalar. `pip` los buscarÃ¡ en el \"Ãndice de Paquetes de Python\" (PyPI), los descargarÃ¡ y los instalarÃ¡ en tu entorno. ğŸ“¥\n",
    "\n",
    "**DescripciÃ³n de los paquetes:** ğŸ“š\n",
    "\n",
    "- **`langchain`:** Es un framework que simplifica la creaciÃ³n de aplicaciones que utilizan modelos de lenguaje grandes (LLMs). Piensa en ello como un conjunto de herramientas para conectar LLMs con otras fuentes de datos y lÃ³gica. ğŸ¤–\n",
    "- **`langchain_ollama`:** Una integraciÃ³n especÃ­fica para usar modelos de lenguaje de la plataforma Ollama dentro de Langchain. Ollama te permite ejecutar LLMs localmente. ğŸ§ \n",
    "- **`dotenv`:** Permite cargar variables de entorno desde un archivo `.env`. Esto es Ãºtil para guardar informaciÃ³n sensible (como claves de API) fuera de tu cÃ³digo. ğŸ”’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d30b6f7-3bec-4d9f-af50-43dfdc81ae6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:42.364369Z",
     "start_time": "2024-05-15T08:19:42.359273Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U pip langgraph langchain_ollama dotenv langchain-google-genai langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1e4f5",
   "metadata": {},
   "source": [
    "### ğŸ“ **Carga de dependencias**\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "```\n",
    "- ğŸ“Œ **`from dotenv import load_dotenv`**: Importa la funciÃ³n `load_dotenv` de `dotenv`, que carga las variables de entorno desde un archivo `.env`.\n",
    "- ğŸ“Œ **`import os`**: Importa el mÃ³dulo `os`, que permite interactuar con el sistema operativo (por ejemplo, acceder a variables de entorno).\n",
    "\n",
    " ğŸ”„ **Carga de variables de entorno**\n",
    "```python\n",
    "load_dotenv()\n",
    "```\n",
    "- ğŸš€ **`load_dotenv()`**: Carga las variables de entorno desde el archivo `.env` en el directorio actual. Esto es Ãºtil para gestionar claves API, rutas, etc., sin hardcodearlas en el cÃ³digo.\n",
    "\n",
    " ğŸ“ **DefiniciÃ³n de carpeta de trabajo**\n",
    "```python\n",
    "workfolder = os.getenv('WORKFOLDER')\n",
    "```\n",
    "- ğŸ—‚ï¸ **`os.getenv('WORKFOLDER')`**: Obtiene el valor de la variable de entorno `WORKFOLDER`, que probablemente define una carpeta donde se guardarÃ¡n los archivos o datos del proyecto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c2f3de-c730-4aec-85a6-af2c2f058803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:42.395571Z",
     "start_time": "2024-05-15T08:19:42.365662Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "load_dotenv()\n",
    "workfolder = os.getenv('WORKFOLDER')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2516e00",
   "metadata": {},
   "source": [
    "### ğŸ§© Bloque 1: Importaciones\n",
    "```python\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "```\n",
    "- Se importan las librerÃ­as necesarias: `ChatOllama` para usar un modelo de lenguaje y `create_react_agent` para crear un agente de LangChain.\n",
    "- `ChatGoogleGenerativeAI` es una versiÃ³n alternativa para Google Generative AI.\n",
    "\n",
    "### ğŸ§  Bloque 2: Definir el modelo de lenguaje LLM\n",
    "```python\n",
    "llm_model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2)\n",
    "llm_model = ChatOllama(model=\"qwen3\")\n",
    "llm_config = {\"recursion_limit\": 10}\n",
    "```\n",
    "- Se define el modelo de LLM que se utilizarÃ¡: `ChatGoogleGenerativeAI` con un modelo especÃ­fico y una temperatura para la generaciÃ³n de texto.\n",
    "- `ChatOllama` es otro modelo de lenguaje que se puede usar.\n",
    "- ğŸ”„ **`llm_config`**: Define una configuraciÃ³n para el modelo de lenguaje.\n",
    "  - ğŸ§  **`\"recursion_limit\": 20`**: Limita la profundidad de la recursiÃ³n para evitar bucles infinitos.\n",
    "\n",
    "\n",
    "### ğŸ§  Bloque 3: Crear el Agente\n",
    "```python\n",
    "simple_agent = create_react_agent(name=\"simple_agent\", model=ChatOllama(model=\"qwen3\"), tools=[])\n",
    "```\n",
    "- Se crea un agente llamado `simple_agent` usando el modelo `qwen3` de Ollama. No se le asignan herramientas (tools) por ahora. ğŸ˜\n",
    "\n",
    "### ğŸ“„ Bloque 4: Mensaje de Entrada\n",
    "```python\n",
    "input_message = {\"role\": \"user\", \"content\": \"\"\"\n",
    "Generate the python code for a function that writes a string content in a file. \n",
    "a langchain tool with Annotated parameters and return type.\n",
    "3 parameters: content, file_path and append (True or False)\n",
    "should be able to handle exceptions and return an error message if the file cannot be written.\n",
    "Function must have a 30 words docstring\n",
    "use encoding utf8\n",
    "give just the code, no introduction /no_think\"\"\"\n",
    "}\n",
    "```\n",
    "- Se pide que se genere un cÃ³digo de funciÃ³n en Python para escribir un contenido en un archivo, con anotaciones, manejo de excepciones y una documentaciÃ³n especÃ­fica. ğŸ“\n",
    "\n",
    "### ğŸš€ Bloque 5: Usar el Agente\n",
    "```python\n",
    "for step in simple_agent.stream(\n",
    "    {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()\n",
    "```\n",
    "- Se usa el agente para procesar el mensaje de entrada. El resultado se muestra en pantalla usando `pretty_print()`. ğŸ§ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46fed548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "Generate the python code for a function that writes a string content in a file. \n",
      "a langchain tool with Annotated parameters and return type.\n",
      "3 parameters: content, file_path and append (True or False)\n",
      "should be able to handle exceptions and return an error message if the file cannot be written.\n",
      "Function must have a 30 words docstring\n",
      "use encoding utf8\n",
      "give just the code, no introduction /no_think\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: simple_agent\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "```python\n",
      "from langchain.tools import tool\n",
      "from typing import Annotated\n",
      "import logging\n",
      "\n",
      "@tool\n",
      "def write_to_file(\n",
      "    content: Annotated[str, \"The content to write to the file\"],\n",
      "    file_path: Annotated[str, \"The path to the file\"],\n",
      "    append: Annotated[bool, \"Whether to append to the file or overwrite it\"]\n",
      ") -> Annotated[str, \"Result message indicating success or error\"]:\n",
      "    \"\"\"\n",
      "    Writes content to a file with UTF-8 encoding. Handles exceptions and returns error message on failure.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        mode = 'a' if append else 'w'\n",
      "        with open(file_path, mode, encoding='utf-8') as f:\n",
      "            f.write(content)\n",
      "        return f\"Successfully wrote content to {file_path}\"\n",
      "    except Exception as e:\n",
      "        logging.error(f\"Error writing to file: {e}\")\n",
      "        return f\"Failed to write to file: {str(e)}\"\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm_model = ChatOllama(model=\"qwen3\")\n",
    "# llm_model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2)\n",
    "# llm_model = ChatOpenAI(model=\"qwen-plus\", api_key=os.getenv('DASHSCOPE_API_KEY'), base_url=os.getenv('DASHSCOPE_BASE_URL'))\n",
    "\n",
    "llm_config = {\"recursion_limit\": 10}\n",
    "\n",
    "simple_agent = create_react_agent(name=\"simple_agent\", model=llm_model, tools=[])\n",
    "\n",
    "input_message = {\"role\": \"user\", \"content\": \"\"\"\n",
    "Generate the python code for a function that writes a string content in a file. \n",
    "a langchain tool with Annotated parameters and return type.\n",
    "3 parameters: content, file_path and append (True or False)\n",
    "should be able to handle exceptions and return an error message if the file cannot be written.\n",
    "Function must have a 30 words docstring\n",
    "use encoding utf8\n",
    "give just the code, no introduction /no_think\"\"\"\n",
    "}\n",
    "\n",
    "# Use the agent\n",
    "for step in simple_agent.stream(\n",
    "    {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e09131",
   "metadata": {},
   "source": [
    "### ğŸ”¹ **Bloque 1: Importaciones**\n",
    "### ğŸ”¹ **Bloque 2: DefiniciÃ³n de la funciÃ³n `write_file`**\n",
    "```python\n",
    "@tool\n",
    "def write_file(\n",
    "    content: Annotated[str, \"The content to be written to the file.\"],\n",
    "    file_path: Annotated[str, \"The path to the file where content will be written.\"],\n",
    "    append: Annotated[bool, \"If True, append to the file; if False, overwrite it.\"],\n",
    "    encoding: Annotated[Optional[str], \"The encoding of the file.\"] = 'utf-8'\n",
    ") -> Annotated[str, \"Result message indicating success or error.\"]:\n",
    "```\n",
    "- **Â¿QuÃ© hace?** Define una funciÃ³n llamada `write_file` que es una herramienta (por el decorador `@tool`). ğŸ› ï¸\n",
    "- **Â¿QuÃ© recibe?** \n",
    "  - `content`: El contenido a escribir. ğŸ“\n",
    "  - `file_path`: La ruta del archivo. ğŸ—‚ï¸\n",
    "  - `append`: Si es `True`, se aÃ±ade al final; si es `False`, se sobrescribe. âœ…\n",
    "  - `encoding`: CodificaciÃ³n del archivo (por defecto `utf-8`). ğŸ”\n",
    "- **Â¿QuÃ© devuelve?** Un mensaje que indica si se escribiÃ³ correctamente o hubo un error. ğŸ’¬\n",
    "\n",
    "### ğŸ”¹ **Bloque 3: LÃ³gica de escritura del archivo**\n",
    "```python\n",
    "    \"\"\"Writes content to a file in append or overwrite mode.\"\"\"\n",
    "    try:\n",
    "        mode = 'a' if append else 'w'\n",
    "        content = '\\n'+content if append else content\n",
    "        with open(file_path, mode, encoding=encoding) as f:\n",
    "            f.write(content)\n",
    "        return f\"Content successfully written to {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing to file: {str(e)}\"\n",
    "```\n",
    "- **Â¿QuÃ© hace?** \n",
    "  - **`mode = 'a' if append else 'w'`**: Define el modo de apertura del archivo (`'a'` para anexar, `'w'` para sobrescribir). ğŸ“\n",
    "  - **`content = '\\n'+content if append else content`**: Si se estÃ¡ anexando, agrega una nueva lÃ­nea al contenido. ğŸ“„\n",
    "  - **`with open(...) as f`**: Abre el archivo con los parÃ¡metros definidos. ğŸšª\n",
    "  - **`f.write(content)`**: Escribe el contenido en el archivo. âœï¸\n",
    "  - **`return ...`**: Devuelve un mensaje de Ã©xito o error. ğŸš¨\n",
    "- **Â¿Por quÃ© el `try-except`?** Para manejar errores en caso de que algo vaya mal, como que el archivo no exista o no se tenga permiso. âš ï¸\n",
    "\n",
    "### ğŸ”¹ **Bloque 4: Llamada a la funciÃ³n**\n",
    "```python\n",
    "write_file.invoke(input={'content':'this is a test\\n', 'file_path':'/tmp4/file.txt', 'append': True})\n",
    "```\n",
    "- **Â¿QuÃ© hace?** Llama a la funciÃ³n `write_file` con los parÃ¡metros especificados. ğŸ“¡\n",
    "- **Â¿QuÃ© pasa?** \n",
    "  - Escribe el contenido `'this is a test\\n'` en el archivo `/tmp4/file.txt`.\n",
    "  - Como `append` es `True`, se aÃ±ade al final del archivo. ğŸ“\n",
    "- **Â¿DÃ³nde se guarda?** En la ruta `/tmp4/file.txt`. ğŸ—‚ï¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240354bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Error writing to file: [Errno 2] No such file or directory: '/tmp4/file.txt'\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from typing import Annotated, Optional\n",
    "\n",
    "@tool\n",
    "def write_file(\n",
    "    content: Annotated[str, \"The content to be written to the file.\"],\n",
    "    file_path: Annotated[str, \"The path to the file where content will be written.\"],\n",
    "    append: Annotated[bool, \"If True, append to the file; if False, overwrite it.\"],\n",
    "    encoding: Annotated[Optional[str], \"The encoding of the file.\"] = 'utf-8'\n",
    ") -> Annotated[str, \"Result message indicating success or error.\"]:\n",
    "    \"\"\"Writes content to a file in append or overwrite mode.\"\"\"\n",
    "    try:\n",
    "        mode = 'a' if append else 'w'\n",
    "        content = '\\n'+content if append else content\n",
    "        with open(file_path, mode, encoding=encoding) as f:\n",
    "            f.write(content)\n",
    "        return f\"Content successfully written to {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing to file: {str(e)}\"\n",
    "\n",
    "write_file.invoke(input={'content':'this is a test\\n', 'file_path':'/tmp4/file.txt', 'append': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a938689",
   "metadata": {},
   "source": [
    "**Mensaje de entrada del usuario**  \n",
    "```python src/1.client mail agents.ipynb\n",
    "input_message = {\"role\": \"user\", \"content\": f\"\"\"\n",
    "generate a csv list of 10 dummy clients with the following columns:\n",
    "id, name, address, phone, email, prefered_languaje\n",
    "write the list to file in '{workfolder}/clients.csv'\n",
    "/no_think\"\"\"\n",
    "}\n",
    "```\n",
    "ğŸ“ **ExplicaciÃ³n:** Se define un mensaje de entrada del usuario que solicita generar una lista de 10 clientes ficticios en formato CSV, con columnas especÃ­ficas, y guardar el archivo en una carpeta especÃ­fica.  \n",
    "ğŸ¯ *El usuario pide que se genere un archivo CSV con datos de clientes.*\n",
    "\n",
    "**3. Uso del agente para procesar la solicitud**  \n",
    "ğŸ¤– **ExplicaciÃ³n:** AquÃ­ se usa el agente para procesar el mensaje de entrada. El agente genera una respuesta, y se imprime el Ãºltimo mensaje de la conversaciÃ³n en un formato legible.  \n",
    "ğŸ“¦ *El agente genera el CSV y lo escribe en el archivo especificado.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5dc4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "generate a csv list of 10 dummy clients with the following columns:\n",
      "id, name, address, phone, email, prefered_languaje\n",
      "write the list to file in '/home/daimler/workspaces/agents-course-huggingface/.workspace/clients.csv'\n",
      "/no_think\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: simple_agent\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "Tool Calls:\n",
      "  write_file (4f614abf-4e4d-47c7-b673-3ddc618d3181)\n",
      " Call ID: 4f614abf-4e4d-47c7-b673-3ddc618d3181\n",
      "  Args:\n",
      "    append: False\n",
      "    content: id,name,address,phone,email,prefered_languaje\n",
      "1,John Doe,123 Main St,555-1234,john@example.com,English\n",
      "2,Jane Smith,456 Oak St,555-5678,jane@example.com,Spanish\n",
      "3,Mike Johnson,789 Pine St,555-9012,mike@example.com,French\n",
      "4,Sarah Williams,321 Maple St,555-3456,sarah@example.com,German\n",
      "5,David Brown,654 Birch St,555-7890,david@example.com,Italian\n",
      "6,Emily Davis,987 Cedar St,555-1122,emily@example.com,Dutch\n",
      "7,Robert Wilson,234 Elm St,555-4321,robert@example.com,Portuguese\n",
      "8,Olivia Taylor,567 Walnut St,533-5555,olivia@example.com,Japanese\n",
      "9,William Moore,876 Oak St,555-6789,william@example.com,Korean\n",
      "10,Charlotte Anderson,112 Pine St,555-2233,charlotte@example.com,Chinese\n",
      "    file_path: /home/daimler/workspaces/agents-course-huggingface/.workspace/clients.csv\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: write_file\n",
      "\n",
      "Content successfully written to /home/daimler/workspaces/agents-course-huggingface/.workspace/clients.csv\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: simple_agent\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The CSV file with 10 dummy client entries has been successfully created at the specified path: `/home/daimler/workspaces/agents-course-huggingface/.workspace/clients.csv`. Let me know if you need the file content or further assistance!\n"
     ]
    }
   ],
   "source": [
    "simple_agent = create_react_agent(name=\"simple_agent\", model=llm_model, tools=[write_file])\n",
    "\n",
    "input_message = {\"role\": \"user\", \"content\": f\"\"\"\n",
    "generate a csv list of 10 dummy clients with the following columns:\n",
    "id, name, address, phone, email, prefered_languaje\n",
    "write the list to file in '{workfolder}/clients.csv'\n",
    "/no_think\"\"\"\n",
    "}\n",
    "\n",
    "# Use the agent\n",
    "for step in simple_agent.stream(\n",
    "    {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27747adc",
   "metadata": {},
   "source": [
    "### 1. **CreaciÃ³n del cÃ³digo de la segunda Tool** ğŸ˜Š  \n",
    "```python\n",
    "input_message = {\"role\": \"user\", \"content\": f\"\"\"\n",
    "Generate the python code for a function that return dict with all the client details for a given id. \n",
    "read clients from csv file_path in utf8\n",
    "is a langchain tool with typing Annotated params.\n",
    "params: id: int, file_path: str, encoding: Optional[str] = 'utf-8'\n",
    "handle exceptions\n",
    "Function must have a 20 word docstring\n",
    "give just the code, no introduction /no_think\"\"\"\n",
    "}\n",
    "```\n",
    "- **Â¿QuÃ© hace?** Define un mensaje de entrada que simula una peticiÃ³n del usuario para generar cÃ³digo.  \n",
    "- **Detalles:** Contiene instrucciones sobre cÃ³mo debe ser la funciÃ³n, incluyendo parÃ¡metros, manejo de excepciones y una docstring especÃ­fica.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4024eb89-843d-4cc3-ab3f-e1eb4d031179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:44.477064Z",
     "start_time": "2024-05-15T08:19:42.397083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "Generate the python code for a function that return dict with all the client details for a given id. \n",
      "read clients from csv file_path in utf8\n",
      "is a langchain tool with typing Annotated params.\n",
      "params: id: int, file_path: str, encoding: Optional[str] = 'utf-8'\n",
      "handle exceptions\n",
      "Function must have a 20 word docstring\n",
      "give just the code, no introduction /no_think\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: simple_agent\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "from typing import Annotated, Dict, Optional\n",
      "from langchain.tools import tool\n",
      "import csv\n",
      "\n",
      "@tool\n",
      "def get_client_details(\n",
      "    id: Annotated[int, \"Client ID to retrieve details for\"],\n",
      "    file_path: Annotated[str, \"Path to the CSV file containing client data\"],\n",
      "    encoding: Optional[Annotated[str, \"File encoding, default is 'utf-8'\"]] = 'utf-8'\n",
      ") -> Dict[str, str]:\n",
      "    \"\"\"Retrieve client details by ID from a CSV file. Handles exceptions and returns a dictionary.\"\"\"\n",
      "    try:\n",
      "        with open(file_path, mode='r', encoding=encoding) as file:\n",
      "            reader = csv.DictReader(file)\n",
      "            for row in reader:\n",
      "                if int(row['id']) == id:\n",
      "                    return dict(row)\n",
      "            return {}\n",
      "    except Exception as e:\n",
      "        print(f\"An error occurred: {e}\")\n",
      "        return {}\n"
     ]
    }
   ],
   "source": [
    "input_message = {\"role\": \"user\", \"content\": f\"\"\"\n",
    "Generate the python code for a function that return dict with all the client details for a given id. \n",
    "read clients from csv file_path in utf8\n",
    "is a langchain tool with typing Annotated params.\n",
    "params: id: int, file_path: str, encoding: Optional[str] = 'utf-8'\n",
    "handle exceptions\n",
    "Function must have a 20 word docstring\n",
    "give just the code, no introduction /no_think\"\"\"\n",
    "}\n",
    "\n",
    "# Use the agent\n",
    "for step in simple_agent.stream({\"messages\": [input_message]}, llm_config, stream_mode=\"values\"):\n",
    "    step[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c389a",
   "metadata": {},
   "source": [
    "### ğŸ“ **DefiniciÃ³n de la funciÃ³n `get_client_details`**  \n",
    "La funciÃ³n se llama `get_client_details` y recibe tres parÃ¡metros:  \n",
    "- `id`: El ID del cliente que queremos buscar.  \n",
    "- `file_path`: La ruta del archivo CSV donde estÃ¡n los datos de los clientes.  \n",
    "- `encoding`: La codificaciÃ³n del archivo (por defecto es `'utf-8'`).  \n",
    "\n",
    "La funciÃ³n devuelve un diccionario con los detalles del cliente o un error si algo saliÃ³ mal.\n",
    "\n",
    "### ğŸ§  **Bloque `try`**  \n",
    "Este bloque intenta leer el archivo CSV y buscar el cliente por su ID.  \n",
    "```python\n",
    "with open(file_path, mode='r', encoding=encoding) as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        if int(row['id']) == id:\n",
    "            return dict(row)\n",
    "    return {}\n",
    "```\n",
    "- Abre el archivo en modo lectura (`'r'`).  \n",
    "- Usa `csv.DictReader` para leer el archivo como un diccionario.  \n",
    "- Recorre cada fila del CSV y compara el ID del cliente con el `id` proporcionado.  \n",
    "- Si encuentra un cliente con el mismo ID, devuelve su informaciÃ³n como un diccionario.  \n",
    "- Si no lo encuentra, devuelve un diccionario vacÃ­o `{}`.\n",
    "\n",
    "### âš ï¸ **Bloque `except`**  \n",
    "Si ocurre un error durante la lectura del archivo (por ejemplo, el archivo no existe o tiene un formato incorrecto), se captura y se devuelve un mensaje de error.\n",
    "```python\n",
    "except Exception as e:\n",
    "    return {\"error\": str(e)}\n",
    "```\n",
    "- Captura cualquier excepciÃ³n y la convierte en un mensaje de error.  \n",
    "- Devuelve un diccionario con la clave `\"error\"` y el mensaje de error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53db0c78-e357-48ba-ae5f-3fc04735a3b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:48.810290Z",
     "start_time": "2024-05-15T08:19:46.561088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '6',\n",
       " 'name': 'Emily Davis',\n",
       " 'address': '987 Cedar St',\n",
       " 'phone': '555-1122',\n",
       " 'email': 'emily@example.com',\n",
       " 'prefered_languaje': 'Dutch'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool \n",
    "from typing import Dict, Annotated, Optional\n",
    "import csv\n",
    "\n",
    "@tool\n",
    "def get_client_details(\n",
    "    id: Annotated[int, \"Client ID to retrieve details for\"],\n",
    "    file_path: Annotated[str, \"Path to the CSV file containing client data\"],\n",
    "    encoding: Optional[Annotated[str, \"File encoding, default is 'utf-8'\"]] = 'utf-8'\n",
    ") -> Dict[str, any]:\n",
    "    \"\"\"Retrieve client details by ID\"\"\"\n",
    "    try:\n",
    "        with open(file_path, mode='r', encoding=encoding) as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                if int(row['id']) == id:\n",
    "                    return dict(row)\n",
    "            return {}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "get_client_details.invoke(input={'id':6, 'file_path': f'{workfolder}/clients.csv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b33b322",
   "metadata": {},
   "source": [
    "**Bloque 1: Crear un mensaje de entrada**  \n",
    "```python\n",
    "input_message = {\"role\": \"user\", \"content\": f\"\"\"\n",
    "get the client details of a client with id '{random.randint(0, 10)}'\n",
    "file is in {workfolder}/clients.csv\n",
    "generate an email explaining we could not deliver the package at his address nor contact him at his phone number.\n",
    "use they prefered language\n",
    "especify the actual address and phone number of the client.\n",
    "\"\"\"\n",
    "}\n",
    "```\n",
    "- **Â¿QuÃ© hace?** Crea un mensaje de entrada en formato JSON que simula una consulta de un usuario.  \n",
    "- **Detalles:**  \n",
    "  - Pide los detalles de un cliente con un ID aleatorio entre 0 y 10. ğŸ˜Š  \n",
    "  - Indica que los datos estÃ¡n en un archivo CSV llamado `clients.csv` en la carpeta `workfolder`. ğŸ—‚ï¸  \n",
    "  - Solicita generar un email explicando que no se pudo entregar el paquete ni contactar al cliente. ğŸ“§  \n",
    "  - Menciona usar el idioma preferido del cliente. ğŸŒ  \n",
    "  - Pide especificar la direcciÃ³n y el nÃºmero de telÃ©fono del cliente. ğŸ“\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a7a1260-d9f6-4011-b2b1-13fab5126997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:48.825649Z",
     "start_time": "2024-05-15T08:19:48.811753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "get the client details of a client with id '10'\n",
      "file is in /home/daimler/workspaces/agents-course-huggingface/.workspace/clients.csv\n",
      "generate an email explaining we could not deliver the package at his address nor contact him at his phone number.\n",
      "use they prefered language\n",
      "especify the actual address and phone number of the client.\n",
      "/no_think\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: simple_agent\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "Tool Calls:\n",
      "  get_client_details (1f43b4b7-0741-4bb8-bd46-19d7571a0905)\n",
      " Call ID: 1f43b4b7-0741-4bb8-bd46-19d7571a0905\n",
      "  Args:\n",
      "    file_path: /home/daimler/workspaces/agents-course-huggingface/.workspace/clients.csv\n",
      "    id: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_client_details\n",
      "\n",
      "{\"id\": \"10\", \"name\": \"Charlotte Anderson\", \"address\": \"112 Pine St\", \"phone\": \"555-2233\", \"email\": \"charlotte@example.com\", \"prefered_languaje\": \"Chinese\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: simple_agent\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Subject: æ— æ³•é€è¾¾åŒ…è£¹é€šçŸ¥\n",
      "\n",
      "å°Šæ•¬çš„å®‰å¾·æ£®å¥³å£«ï¼Œ\n",
      "\n",
      "æˆ‘ä»¬å°è¯•å°†åŒ…è£¹é€è¾¾æ‚¨æä¾›çš„åœ°å€ï¼š112 Pine Stï¼Œä½†æœªèƒ½æˆåŠŸé€è¾¾ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿå°è¯•é€šè¿‡æ‚¨æä¾›çš„ç”µè¯å·ç  555-2233 ä¸æ‚¨è”ç³»ï¼Œä½†æœªèƒ½æ¥é€šã€‚\n",
      "\n",
      "æˆ‘ä»¬å¾ˆæŠ±æ­‰ç»™æ‚¨å¸¦æ¥ä¸ä¾¿ï¼Œå¹¶å¸Œæœ›èƒ½å°½å¿«ä¸æ‚¨è”ç³»ä»¥è§£å†³æ­¤é—®é¢˜ã€‚å¦‚æœæ‚¨èƒ½æä¾›æ–°çš„åœ°å€æˆ–è”ç³»æ–¹å¼ï¼Œæˆ‘ä»¬å°†éå¸¸æ„Ÿæ¿€ã€‚\n",
      "\n",
      "ç¥å¥½ï¼Œ\n",
      "\n",
      "å¿«é€’æœåŠ¡å›¢é˜Ÿ\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "import random\n",
    "\n",
    "simple_agent = create_react_agent(name=\"simple_agent\", model=llm_model, tools=[get_client_details])\n",
    "\n",
    "input_message = {\"role\": \"user\", \"content\": f\"\"\"\n",
    "get the client details of a client with id '{random.randint(0, 10)}'\n",
    "file is in {workfolder}/clients.csv\n",
    "generate an email explaining we could not deliver the package at his address nor contact him at his phone number.\n",
    "use they prefered language\n",
    "especify the actual address and phone number of the client.\n",
    "/no_think\"\"\"\n",
    "}\n",
    "\n",
    "# Use the agent\n",
    "for step in simple_agent.stream(\n",
    "    {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
